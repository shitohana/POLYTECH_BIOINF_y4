Скрытые Марковские модели

# Введение

HMM (Hidden Markov Models, Скрытые марковские модели) -- это мощные статистические методы, позволяющие моделировать биологические последовательности и выявлять скрытые стохастические процессы, которые управляют их формированием.

![](_files/hmm/hmm_scheme.jpeg){fig-alt="https://www.google.com/url?sa=i&url=https%3A%2F%2Fm.youtube.com%2Fwatch%3Fv%3DRWkHJnFj5rY&psig=AOvVaw18rQYPNv-xvGZq_2Gi1Trd&ust=1731420593170000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCNDK3ry61IkDFQAAAAAdAAAAABAT" fig-align="center"}

В биоинформатике HMM используются для анализа последовательностей, предсказания генов и обнаружения мотивов. Они особенно полезны в задачах, связанных с последовательными данными, где скрытые состояния (такие как, например, кодирующие и некодирующие регионы) оказывают влияние на наблюдаемые события (например, нуклеотидные последовательности).

HMM широко применяются для предсказания генов, помогая определить кодирующие участки ДНК и, таким образом, позволяют продолжить изучение структуры и функции генов. Они также используются в множественном выравнивании последовательностей, что помогает сопоставлять родственные последовательности и изучать эволюционные взаимосвязи.

![](_files/hmm/hmm_scheme_seq.jpeg){fig-align="center"}

# Практическое задание

Данное практическое занятие будет посвящено применению HMM для поиска CpG-островков в геноме.

### Как подготовить HMM?

Марковская модель описывает систему, которая переходит из одного состояния в другое, причем каждый переход зависит исключительно от текущего состояния (т.н. марковское свойство). Это означает, что будущее состояние системы определяется только ее текущим состоянием, а не всей предшествующей последовательностью событий.

Ключевые параметры для настройки модели:

-   Состояния: Определите различные состояния, которые система может занимать.

-   Вероятности переходов: Укажите вероятности перехода из одного состояния в другое. Эти вероятности должны суммироваться до 1 для любого состояния, отражая все возможные пути, которые система может выбрать.

-   Начальные вероятности состояний: Задайте вероятности для того, чтобы система начала с определенного состояния. Эти вероятности используются для инициализации модели в начале последовательности.

## Предисловие

### Что такое CpG-островки?

CpG-островки --- это специфические участки ДНК с высокой частотой сочетаний цитозина и гуанина (обозначаемых как CpG), которые играют важную роль в регуляции генов. Эти островки часто располагаются рядом с промоторами --- участками, ответственными за запуск транскрипции генов, --- особенно в геномах эукариот.

![](_files/hmm/cpg_island.jpeg){fig-align="center"}

Одной из ключевых особенностей CpG-островков в промоторных областях является то, что они обычно остаются неметилированными, что способствует активной экспрессии гена. Напротив, их метилирование может приводить к «выключению» гена, подавляя его активность. Поэтому состояние CpG-островков --- метилированное или неметилированное --- становится своего рода переключателем, который помогает регулировать, будет ли ген экспрессироваться или нет.

![](_files/hmm/cpg_island2.png){style="background-color: white" fig-align="center"}

## Алгоритм Витерби (reminder)

Алгоритм Витерби --- это метод динамического программирования, который позволяет определить наиболее вероятную последовательность скрытых состояний в скрытой марковской модели (HMM) для данной последовательности наблюдаемых событий. Алгоритм вычисляет путь, который максимизирует вероятность наблюдаемой последовательности, путем итеративного расчета наивысшей вероятности для каждого состояния на каждом этапе. При этом сохраняется информация как о вероятностях, так и о «указателях» (backpointer), необходимых для восстановления оптимального пути по завершении расчетов. Благодаря рекурсивному подходу алгоритм эффективно отслеживает путь, ведущий к каждому состоянию, избегая необходимости полного перебора всех возможных путей.

Почему выбран алгоритм Витерби для данной задачи? Алгоритм Витерби особенно подходит для выявления CpG-островков в последовательностях ДНК, так как он позволяет точно расшифровать последовательность в разные состояния (например, «CpG-островок» и «не-CpG-островок») на основе HMM. Высокая вычислительная эффективность делает его идеальным инструментом для анализа длинных последовательностей ДНК, типичных для биоинформатических исследований. Определяя наиболее вероятную последовательность скрытых состояний, алгоритм помогает выявлять биологически значимые области с высоким содержанием CG, что связано с функциями регуляции генов.

Aлгоритм Витерби находит широкое применение в различных областях биоинформатики и вычислительной биологии. Например, он используется для предсказания генов, помогая определить расположение экзонов и интронов в геномной последовательности. Алгоритм также применяется в множественном выравнивании последовательностей, где он помогает выровнять родственные биологические последовательности и выявить консервативные регионы. За пределами биоинформатики алгоритм Витерби также используется в системах распознавания речи, языковом моделировании и робототехнике для определения наиболее вероятной последовательности состояний в различных марковских системах.

### Как подготовить HMM. Частный случай.

Состояния: В этой HMM предусмотрены два состояния --- «CpG-островок» и «не-CpG-островок». Состояние CpG-островка представляет области генома с высокой частотой цитозин-гуаниновых динуклеотидов (CG), тогда как состояние не-CpG-островка охватывает стандартные участки генома с низким содержанием CG.

Вероятности перехода: Вероятности перехода между состояниями определяют, какова вероятность перемещения из одного состояния в другое. Например, вероятность остаться в состоянии CpG-островка может быть высокой, что отражает их цельный, локализованный характер. В то же время вероятность перехода из состояния «не-CpG-островок» в «CpG-островок» может быть ниже, так как CpG-островки обычно сконцентрированы в определенных участках генома, часто около промоторных регионов генов.

Вероятности эмиссии: Вероятности эмиссии описывают вероятность наблюдения конкретных нуклеотидов (A, C, G, T) в каждом состоянии. Для CpG-островков характерна более высокая вероятность появления нуклеотидов C и G, что отражает их уникальный состав, тогда как в не-CpG-областях эти вероятности распределены более равномерно.

Моделирование CpG-островков: Параметры HMM --- состояния, вероятности переходов и вероятности эмиссии --- создают модель, способную распознать CpG-островки на основе их биологических особенностей, таких как высокое содержание CG и их расположение вблизи промоторных областей. Таким образом, модель не только различает CpG и не-CpG участки, но и выделяет те, что с наибольшей вероятностью играют роль в регуляции генов.

Графическое представление: Визуальная схема HMM наглядно отображает модель. В ней состояния представлены узлами, а переходы между ними --- стрелками с указанием вероятностей. Такой граф помогает представить, как система переходит между состояниями и в какой последовательности.

```{mermaid}
stateDiagram-v2
    [*] --> NonCpG

    state "Non-CpG" as NonCpG
    state "CpG Island" as CpG

    NonCpG --> NonCpG : p = 0.999
    NonCpG --> CpG : p = 0.001
    CpG --> CpG : p = 0.995
    CpG --> NonCpG : p = 0.005

    note right of NonCpG
        **Emission Probabilities:**
        A: 0.30
        C: 0.20
        G: 0.20
        T: 0.30
    end note

    note left of CpG
        **Emission Probabilities:**
        A: 0.15
        C: 0.35
        G: 0.35
        T: 0.15
    end note

```

## Имплементация алгоритма

Инициализация матрицы Витерби При работе с алгоритмом Витерби первым шагом является инициализация матрицы, в которой будут храниться вероятности наиболее вероятных путей для каждого состояния на каждом шаге последовательности. Эта матрица позволяет моделировать вероятностный путь через последовательность ДНК, учитывая наиболее вероятные переходы между состояниями.

Итерация по последовательности В процессе итерации по последовательности ДНК, шаг за шагом, вычисляется вероятность нахождения в каждом из возможных состояний (например, «CpG-островок» или «не-CpG-островок») на каждом этапе последовательности. Этот шаг позволяет постепенно накапливать вероятности, связанные с каждым состоянием в последовательности.

Построение и использование матрицы Витерби Создание матрицы Витерби (V): Эта матрица (V) используется для хранения максимальной вероятности достижения каждого состояния в каждый момент последовательности. Дополнительно создается матрица указателей (backpointer), которая сохраняет наиболее вероятное предыдущее состояние для каждого текущего состояния, что будет полезно на этапе определения пути.

Выбор конечного состояния: В последней колонке матрицы V определяется состояние с наивысшей вероятностью, которое считается конечной точкой на наиболее вероятном пути.

Обратный проход (backtracking): Начиная с выбранного конечного состояния, матрица указателей используется для «обратного прохода» через последовательность, чтобы восстановить наиболее вероятный путь скрытых состояний. Этот процесс позволяет точно определить участки, такие как CpG-островки, в анализируемой последовательности.

Пример имплементации алгоритма (псевдокод)

### Входные данные:

-   $O = {o_1, o_2, \dots, o_N}$: Пространство наблюдений
-   $S = {s_1, s_2, \dots, s_K}$: Пространство состояний
-   $Y = {y_1, y_2, \dots, y_T}$: Последовательность наблюдений
-   $A$: Матрица переходов из $i$-го состояния в $j$-е, размером $K \times K$
-   $B$: Матрица эмиссии размера $K \times N$, определяющая вероятность наблюдения $o_j$ из состояния $s_i$
-   $\pi$: Массив начальных вероятностей размером $K$, показывающий вероятность того, что начальное состояние --- $s_i$

```{r, eval = FALSE}
Viterbi(O, S, P, Y, A, B) 
    for j = 1 to K
        TState[j, 1] = P[j] * B[j, Y[1]]
        TIndex[j, 1] = 0
    for i = 2 to T
        for j = 1 to K
            TIndex[j, i] = argmax_k_in_K (TState[k, i-1] * A[k, j] * B[j, Y[i]])
            TState[j, i] = TState[TIndex[j, i], i-1] * A[TIndex[j, i], j] * B[j, Y[i]]
    X[T] = argmax_1 <= k <= K (TState[k, T]) 
    for i = T downto 2
        X[i-1] = TIndex[X[i], i]
    return X
```

# Оценка эффективности модели

## Sensitivity and specificity

**Чувствительность (sensitivity)** и **специфичность (specificity)** --- статистические показатели диагностического теста по выявлению больных и здоровых, выводимых из ошибок первого и второго рода в бинарной классификации. Значения обоих показателей лежат в пределах от 0 до 1.

**Чувствительность** (истинно положительная пропорция) отражает долю положительных результатов, которые правильно идентифицированы как таковые. Иными словами, чувствительность диагностического теста показывает вероятность того, что больной субъект будет классифицирован именно как больной.\[1\]

**Специфичность** (истинно отрицательная пропорция) отражает долю отрицательных результатов, которые правильно идентифицированы как таковые, то есть вероятность того, что не больные субъекты будут классифицированы именно как не больные.\[1\]

Для примера можно рассмотреть группу, некоторые члены которой страдают определённым заболеванием, а остальные --- нет. Предположим, что существует метод для разграничения этих двух долей, но при этом некоторые из здоровых классифицируются как больные, а некоторые из больных --- как здоровые. Под «здоровым» и «больным» будем подразумевать отсутствие или наличие рассматриваемого заболевания. Это иллюстрируется на рисунке ниже «Общая модель чувствительности и специфичности».

![](_files/hmm/specificity.svg){fig-align="center"}

![](_files/hmm/specificity1.svg)

## F-score

F-score, или F-мера, -- это метрика, широко применяемая для оценки качества классификационных моделей, особенно при работе с несбалансированными данными. Она объединяет точность (precision) и полноту (recall) в одно значение. Основная формула F-score выглядит так:

$$
F_β​=(1+\beta^2)⋅\frac{\text{precision}\cdot\text{recall}}{(\beta^2\cdot\text{precision})+\text{recall}}
$$

![](_files/hmm/fscore1.png){fig-align="center"}

### Определения

**Точность (Precision)**: показывает, какая доля предсказанных моделью положительных результатов действительно является положительной. Она определяется как:

$$
\text{precision}=\frac{TP}{TP+FP}
$$

где $TP$ - количество истинных положительных случаев, а $FP$ - количество ложных положительных

**Полнота (Recall)**: отражает, какая доля истинных положительных объектов была найдена моделью. Формула:

$$
\text{recall}=\frac{TP}{TP+FN}
$$

Здесь $FN$ - количество ложных отрицательных случаев

### Параметр $\beta$

Параметр $\beta$ в формуле F-score используется для регулировки относительной важности точности и полноты. Чем больше \$\\beta\$, тем выше значение полноты по отношению к точности. Соответственно, $\beta < 1$ усиливает важность точности. Например:

-   **F1-score** ($\beta$=1) -- точность и полнота равны по весу.

-   **F2-score** ($\beta$=2) -- полнота важнее в два раза, чем точность.

### Применение F-score

F-score широко применяется для оценки классификационных моделей, особенно в случаях, когда данные несбалансированы. В таких ситуациях стандартная точность модели может вводить в заблуждение, так как высокая точность может быть результатом редкого появления положительных классов. Например, в задаче обнаружения мошенничества большинство транзакций обычно честные, и классификатор, прогнозирующий все транзакции как честные, получит высокую точность, хотя он не обнаружит ни одного случая мошенничества. Здесь F-score становится важным инструментом, потому что он учитывает как точность (precision), так и полноту (recall), обеспечивая более сбалансированную оценку.

F-score особенно полезен в задачах информационного поиска, текстовой классификации, медицинской диагностики и других областях, где важно одновременно находить как можно больше значимых объектов (полнота) и минимизировать количество ложных срабатываний (точность). Например, в медицинских тестах при классификации болезни важно не только найти как можно больше положительных случаев (высокая полнота), но и избежать большого количества ложных диагнозов (высокая точность), которые могут вызвать ненужное беспокойство.

Таким образом, F-score является ключевой метрикой в задачах, где важно балансировать между полнотой и точностью, и может быть адаптирован для конкретных потребностей, выбирая подходящее значение параметра $\beta$.

# Домашнее задание

## Цель

Научиться применять скрытую марковскую модель (HMM) для обнаружения CpG-островков в последовательности ДНК, закрепив теоретические знания, полученные на занятиях.

## Задачи

1.  **Определение модели**: Задайте HMM с двумя состояниями («CpG» и «не-CpG»), указав разумные начальные значения для вероятностей переходов и эмиссий.

    ::: callout-note
    Для этого шага Вы можете использовать те же параметры, что и во время практического занятия.
    :::

2.  **Реализация алгоритма**: Реализуйте алгоритм Витерби на Python для поиска CpG-островков в длинной последовательности ДНК. Этот этап опирается на материал, изученный на занятии, где вы узнали, как применять алгоритм Витерби для нахождения наиболее вероятной последовательности состояний. Теперь ваша задача --- применить эти знания к большему и более сложному набору данных.

    ::: callout-note
    В качестве генома для анализа мы будем использовать геном рыбки Данио-рерио (*Danio Rerio*, Zebrafish). Данио-рерио является одним из наиболее изученных позвоночных наряду с крысами и мышами. Одним из преимуществ использования этой рыбы в качестве модельного организма является относительно небольшая длина генома \~1.5Gb.

    Референсную последовательность генома Данио-рерио нужно скачать с сайта UCSC:\
    <http://hgdownload.soe.ucsc.edu/goldenPath/danRer11/bigZips/danRer11.fa.gz>

    Аннотацию CpG островков следует скачаь с помощью UCSC Table Browser (в BED формате):

    <https://genome.ucsc.edu/cgi-bin/hgTables>
    :::

3.  **Обучение алгоритмом Баум-Велша**: Реализуйте алгоритм Баум-Велша для уточнения параметров модели. Этот алгоритм выбран для закрепления навыков, так как он дополняет алгоритм Витерби. В то время как Витерби используется для нахождения наиболее вероятного пути состояний, Баум-Велш позволяет подбирать оптимальные параметры HMM, опираясь исключительно на наблюдаемые данные, когда точные пути состояний неизвестны.

    ::: callout-tip
    Внимательно изучите принцип работы алгоритма: <https://en.wikipedia.org/wiki/Baum–Welch_algorithm>

    Также, в качестве подсказки, приводим алгоритм на псевдокоде:

    ```{pseudocode, eval=FALSE}
    BaumWelch(observations, states, transitions, emissions, max_iterations):
        Initialize transition and emission probabilities
        for iteration in range(max_iterations):
            # Expectation Step (E-Step)
            for each observation sequence:
                Compute forward probabilities (alpha)
                Compute backward probabilities (beta)
            
            # Maximization Step (M-Step)
            for each state i:
                for each state j:
                    Update transition probability from state i to j
                
                for each observation symbol k:
                    Update emission probability for state i to symbol k
        
        return updated transition and emission probabilities
    ```

    А также метод подсчета alpha:

    ```{pseudocode, eval=FALSE}
    ComputeAlpha(observations, states, start_prob, transition_prob, emission_prob):
        Initialize alpha for the first observation:
        for each state i:
            alpha[0][i] = start_prob[i] * emission_prob[i][observations[0]]
        
        # Recursively compute alpha for the rest of the observations
        for t from 1 to length(observations) - 1:
            for each state i:
                alpha[t][i] = 0
                for each state j:
                    alpha[t][i] += alpha[t - 1][j] * transition_prob[j][i]
                alpha[t][i] *= emission_prob[i][observations[t]]
        
        return alpha
    ```

    Метод подсчета beta Вам требуется придумать самим.
    :::

4.  **Сравнение с реальными данными**: Возьмите последовательность ДНК из публичной базы данных (например, NCBI) с известными CpG-островками и проверьте, насколько модель совпадает с существующими аннотациями. Сравнение результатов с реальными данными поможет оценить практическую полезность и точность модели.

5.  **Оценка точности**: Рассчитайте чувствительность, специфичность и F1-метрику для оценки работы модели, обсудив возможные причины расхождений. Эти метрики помогут количественно оценить точность модели и выявить направления для улучшения.

Материалы для сдачи:

1.  **Python-код**: Отправьте документированные скрипты на Python.

2.  **Отчет** (3--5 страниц): Подготовьте подробный отчет, включающий описание подхода, трудностей, анализа чувствительности и результатов.
